# S3 Storage Classes

## S3 Standard - General Purpose

- Availability 99.99%

- Used for frequently accessed data.

- Low latency and high throughput

- It can sustain 2 concurrent facility failures.

- Usecases include - Big data analytics, mobile and gaming applications, content distribution.

## S3 Standard - Infrequent Access (IA)

- Suitable for data that is less frequently accessed, but requires rapid access when needed.

- 99.9% availability

- Lower cost compared to S3 standard, but retrieval fee

- It can sustain 2 concurrent facility failures.

- Usecases - As a data store for disaster recovery, backups

## S3 Intelligent - Tiering

- 99.9% Availability

- Same low latency and high throughput performance of S3 standard.

- Cost optimized by automatically moving objects between two access tier based on changing access patterns:-
  
  - Frequent access
  
  - Infrequent access

- Resilient against events that impact an entire Availability Zone

## S3 One Zone - Infrequent Access (IA)

- Same as IA but data is stored in a single AZ

- 99.5% Availability

- Low latency and high throughput

- Lower cost compared to IA (by 20%)

- Use case - Storing secondary backup copies of on premise data or storing data you can recreate

## Amazon Glacier & Glacier Deep Archive

- Low cost object storage (in GB/month) meant for archiving / backup.

- Data is retained for the longer term (years)

- Various retrieval options of time + fees for retrieval

- **Amazon Glacier** - cheap:
  
  - Expidited (1 to 5 minutes)
  
  - Standard (3 to 5 hours)
  
  - Bulk (5 to 12 hours)

- **Amazon Glacier Deep Archive** - cheapest:
  
  - Standard (12 hours)
  
  - Bulk (48 hours)

## Moving objects between storage classes

- User can transition objects between different storage classes.

- For infrequently accessed objects, move them to standard IA.

- Object not required in real time can be moved to glacier or deep archive

- Moving objects can be configured using a lifecycle configuration.

## S3 and Glacier Lock

- S3 bucket and glacier have  a model that can be followed to lock the files present in the storage.

- The model is called WORM (Write once Read Many)

- In S3, the WORM model will block an object version deletetion for the specified amount of time.

- In glacier, user can define a lock policy. the lock policy itself can not be changed.

- These are useful for compliance and data retention.

# Shared Responsibility Model

For S3, AWS in responsible for:-

- Infrastructure (Global security, durability, availability, sustain concurrent loss)

- Configuration and vulnerability analysis.

- Compliance Validation

Users are responsible for:-

- S3 versioning

- S3 bucket policies

- S3 Replication setup

- Logging and Monitoring

- S3 Storage class

- Data Encryption




